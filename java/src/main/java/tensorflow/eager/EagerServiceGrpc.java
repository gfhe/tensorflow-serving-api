package tensorflow.eager;

import static io.grpc.MethodDescriptor.generateFullMethodName;

/**
 * <pre>
 *&#47;/////////////////////////////////////////////////////////////////////////////
 * Eager Service defines a TensorFlow service that executes operations eagerly
 * on a set of local devices, on behalf of a remote Eager executor.
 * The service impl will keep track of the various clients and devices it has
 * access to and allows the client to enqueue ops on any devices that it is able
 * to access and schedule data transfers from/to any of the peers.
 * A client can generate multiple contexts to be able to independently execute
 * operations, but cannot share data between the two contexts.
 * NOTE: Even though contexts generated by clients should be independent, the
 * lower level tensorflow execution engine is not, so they might share some data
 * (e.g. a Device's ResourceMgr).
 * //////////////////////////////////////////////////////////////////////////////
 * </pre>
 */
@javax.annotation.Generated(
    value = "by gRPC proto compiler (version 1.51.0)",
    comments = "Source: tensorflow/core/protobuf/eager_service.proto")
@io.grpc.stub.annotations.GrpcGenerated
public final class EagerServiceGrpc {

  private EagerServiceGrpc() {}

  public static final String SERVICE_NAME = "tensorflow.eager.EagerService";

  // Static method descriptors that strictly reflect the proto.
  private static volatile io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.CreateContextRequest,
      tensorflow.eager.EagerServiceOuterClass.CreateContextResponse> getCreateContextMethod;

  @io.grpc.stub.annotations.RpcMethod(
      fullMethodName = SERVICE_NAME + '/' + "CreateContext",
      requestType = tensorflow.eager.EagerServiceOuterClass.CreateContextRequest.class,
      responseType = tensorflow.eager.EagerServiceOuterClass.CreateContextResponse.class,
      methodType = io.grpc.MethodDescriptor.MethodType.UNARY)
  public static io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.CreateContextRequest,
      tensorflow.eager.EagerServiceOuterClass.CreateContextResponse> getCreateContextMethod() {
    io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.CreateContextRequest, tensorflow.eager.EagerServiceOuterClass.CreateContextResponse> getCreateContextMethod;
    if ((getCreateContextMethod = EagerServiceGrpc.getCreateContextMethod) == null) {
      synchronized (EagerServiceGrpc.class) {
        if ((getCreateContextMethod = EagerServiceGrpc.getCreateContextMethod) == null) {
          EagerServiceGrpc.getCreateContextMethod = getCreateContextMethod =
              io.grpc.MethodDescriptor.<tensorflow.eager.EagerServiceOuterClass.CreateContextRequest, tensorflow.eager.EagerServiceOuterClass.CreateContextResponse>newBuilder()
              .setType(io.grpc.MethodDescriptor.MethodType.UNARY)
              .setFullMethodName(generateFullMethodName(SERVICE_NAME, "CreateContext"))
              .setSampledToLocalTracing(true)
              .setRequestMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.CreateContextRequest.getDefaultInstance()))
              .setResponseMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.CreateContextResponse.getDefaultInstance()))
              .setSchemaDescriptor(new EagerServiceMethodDescriptorSupplier("CreateContext"))
              .build();
        }
      }
    }
    return getCreateContextMethod;
  }

  private static volatile io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest,
      tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse> getUpdateContextMethod;

  @io.grpc.stub.annotations.RpcMethod(
      fullMethodName = SERVICE_NAME + '/' + "UpdateContext",
      requestType = tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest.class,
      responseType = tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse.class,
      methodType = io.grpc.MethodDescriptor.MethodType.UNARY)
  public static io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest,
      tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse> getUpdateContextMethod() {
    io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest, tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse> getUpdateContextMethod;
    if ((getUpdateContextMethod = EagerServiceGrpc.getUpdateContextMethod) == null) {
      synchronized (EagerServiceGrpc.class) {
        if ((getUpdateContextMethod = EagerServiceGrpc.getUpdateContextMethod) == null) {
          EagerServiceGrpc.getUpdateContextMethod = getUpdateContextMethod =
              io.grpc.MethodDescriptor.<tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest, tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse>newBuilder()
              .setType(io.grpc.MethodDescriptor.MethodType.UNARY)
              .setFullMethodName(generateFullMethodName(SERVICE_NAME, "UpdateContext"))
              .setSampledToLocalTracing(true)
              .setRequestMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest.getDefaultInstance()))
              .setResponseMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse.getDefaultInstance()))
              .setSchemaDescriptor(new EagerServiceMethodDescriptorSupplier("UpdateContext"))
              .build();
        }
      }
    }
    return getUpdateContextMethod;
  }

  private static volatile io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest,
      tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> getEnqueueMethod;

  @io.grpc.stub.annotations.RpcMethod(
      fullMethodName = SERVICE_NAME + '/' + "Enqueue",
      requestType = tensorflow.eager.EagerServiceOuterClass.EnqueueRequest.class,
      responseType = tensorflow.eager.EagerServiceOuterClass.EnqueueResponse.class,
      methodType = io.grpc.MethodDescriptor.MethodType.UNARY)
  public static io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest,
      tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> getEnqueueMethod() {
    io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest, tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> getEnqueueMethod;
    if ((getEnqueueMethod = EagerServiceGrpc.getEnqueueMethod) == null) {
      synchronized (EagerServiceGrpc.class) {
        if ((getEnqueueMethod = EagerServiceGrpc.getEnqueueMethod) == null) {
          EagerServiceGrpc.getEnqueueMethod = getEnqueueMethod =
              io.grpc.MethodDescriptor.<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest, tensorflow.eager.EagerServiceOuterClass.EnqueueResponse>newBuilder()
              .setType(io.grpc.MethodDescriptor.MethodType.UNARY)
              .setFullMethodName(generateFullMethodName(SERVICE_NAME, "Enqueue"))
              .setSampledToLocalTracing(true)
              .setRequestMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.EnqueueRequest.getDefaultInstance()))
              .setResponseMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.EnqueueResponse.getDefaultInstance()))
              .setSchemaDescriptor(new EagerServiceMethodDescriptorSupplier("Enqueue"))
              .build();
        }
      }
    }
    return getEnqueueMethod;
  }

  private static volatile io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest,
      tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> getStreamingEnqueueMethod;

  @io.grpc.stub.annotations.RpcMethod(
      fullMethodName = SERVICE_NAME + '/' + "StreamingEnqueue",
      requestType = tensorflow.eager.EagerServiceOuterClass.EnqueueRequest.class,
      responseType = tensorflow.eager.EagerServiceOuterClass.EnqueueResponse.class,
      methodType = io.grpc.MethodDescriptor.MethodType.BIDI_STREAMING)
  public static io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest,
      tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> getStreamingEnqueueMethod() {
    io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest, tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> getStreamingEnqueueMethod;
    if ((getStreamingEnqueueMethod = EagerServiceGrpc.getStreamingEnqueueMethod) == null) {
      synchronized (EagerServiceGrpc.class) {
        if ((getStreamingEnqueueMethod = EagerServiceGrpc.getStreamingEnqueueMethod) == null) {
          EagerServiceGrpc.getStreamingEnqueueMethod = getStreamingEnqueueMethod =
              io.grpc.MethodDescriptor.<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest, tensorflow.eager.EagerServiceOuterClass.EnqueueResponse>newBuilder()
              .setType(io.grpc.MethodDescriptor.MethodType.BIDI_STREAMING)
              .setFullMethodName(generateFullMethodName(SERVICE_NAME, "StreamingEnqueue"))
              .setSampledToLocalTracing(true)
              .setRequestMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.EnqueueRequest.getDefaultInstance()))
              .setResponseMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.EnqueueResponse.getDefaultInstance()))
              .setSchemaDescriptor(new EagerServiceMethodDescriptorSupplier("StreamingEnqueue"))
              .build();
        }
      }
    }
    return getStreamingEnqueueMethod;
  }

  private static volatile io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest,
      tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse> getWaitQueueDoneMethod;

  @io.grpc.stub.annotations.RpcMethod(
      fullMethodName = SERVICE_NAME + '/' + "WaitQueueDone",
      requestType = tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest.class,
      responseType = tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse.class,
      methodType = io.grpc.MethodDescriptor.MethodType.UNARY)
  public static io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest,
      tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse> getWaitQueueDoneMethod() {
    io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest, tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse> getWaitQueueDoneMethod;
    if ((getWaitQueueDoneMethod = EagerServiceGrpc.getWaitQueueDoneMethod) == null) {
      synchronized (EagerServiceGrpc.class) {
        if ((getWaitQueueDoneMethod = EagerServiceGrpc.getWaitQueueDoneMethod) == null) {
          EagerServiceGrpc.getWaitQueueDoneMethod = getWaitQueueDoneMethod =
              io.grpc.MethodDescriptor.<tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest, tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse>newBuilder()
              .setType(io.grpc.MethodDescriptor.MethodType.UNARY)
              .setFullMethodName(generateFullMethodName(SERVICE_NAME, "WaitQueueDone"))
              .setSampledToLocalTracing(true)
              .setRequestMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest.getDefaultInstance()))
              .setResponseMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse.getDefaultInstance()))
              .setSchemaDescriptor(new EagerServiceMethodDescriptorSupplier("WaitQueueDone"))
              .build();
        }
      }
    }
    return getWaitQueueDoneMethod;
  }

  private static volatile io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest,
      tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse> getRunComponentFunctionMethod;

  @io.grpc.stub.annotations.RpcMethod(
      fullMethodName = SERVICE_NAME + '/' + "RunComponentFunction",
      requestType = tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest.class,
      responseType = tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse.class,
      methodType = io.grpc.MethodDescriptor.MethodType.UNARY)
  public static io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest,
      tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse> getRunComponentFunctionMethod() {
    io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest, tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse> getRunComponentFunctionMethod;
    if ((getRunComponentFunctionMethod = EagerServiceGrpc.getRunComponentFunctionMethod) == null) {
      synchronized (EagerServiceGrpc.class) {
        if ((getRunComponentFunctionMethod = EagerServiceGrpc.getRunComponentFunctionMethod) == null) {
          EagerServiceGrpc.getRunComponentFunctionMethod = getRunComponentFunctionMethod =
              io.grpc.MethodDescriptor.<tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest, tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse>newBuilder()
              .setType(io.grpc.MethodDescriptor.MethodType.UNARY)
              .setFullMethodName(generateFullMethodName(SERVICE_NAME, "RunComponentFunction"))
              .setSampledToLocalTracing(true)
              .setRequestMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest.getDefaultInstance()))
              .setResponseMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse.getDefaultInstance()))
              .setSchemaDescriptor(new EagerServiceMethodDescriptorSupplier("RunComponentFunction"))
              .build();
        }
      }
    }
    return getRunComponentFunctionMethod;
  }

  private static volatile io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest,
      tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse> getKeepAliveMethod;

  @io.grpc.stub.annotations.RpcMethod(
      fullMethodName = SERVICE_NAME + '/' + "KeepAlive",
      requestType = tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest.class,
      responseType = tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse.class,
      methodType = io.grpc.MethodDescriptor.MethodType.UNARY)
  public static io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest,
      tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse> getKeepAliveMethod() {
    io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest, tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse> getKeepAliveMethod;
    if ((getKeepAliveMethod = EagerServiceGrpc.getKeepAliveMethod) == null) {
      synchronized (EagerServiceGrpc.class) {
        if ((getKeepAliveMethod = EagerServiceGrpc.getKeepAliveMethod) == null) {
          EagerServiceGrpc.getKeepAliveMethod = getKeepAliveMethod =
              io.grpc.MethodDescriptor.<tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest, tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse>newBuilder()
              .setType(io.grpc.MethodDescriptor.MethodType.UNARY)
              .setFullMethodName(generateFullMethodName(SERVICE_NAME, "KeepAlive"))
              .setSampledToLocalTracing(true)
              .setRequestMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest.getDefaultInstance()))
              .setResponseMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse.getDefaultInstance()))
              .setSchemaDescriptor(new EagerServiceMethodDescriptorSupplier("KeepAlive"))
              .build();
        }
      }
    }
    return getKeepAliveMethod;
  }

  private static volatile io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.CloseContextRequest,
      tensorflow.eager.EagerServiceOuterClass.CloseContextResponse> getCloseContextMethod;

  @io.grpc.stub.annotations.RpcMethod(
      fullMethodName = SERVICE_NAME + '/' + "CloseContext",
      requestType = tensorflow.eager.EagerServiceOuterClass.CloseContextRequest.class,
      responseType = tensorflow.eager.EagerServiceOuterClass.CloseContextResponse.class,
      methodType = io.grpc.MethodDescriptor.MethodType.UNARY)
  public static io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.CloseContextRequest,
      tensorflow.eager.EagerServiceOuterClass.CloseContextResponse> getCloseContextMethod() {
    io.grpc.MethodDescriptor<tensorflow.eager.EagerServiceOuterClass.CloseContextRequest, tensorflow.eager.EagerServiceOuterClass.CloseContextResponse> getCloseContextMethod;
    if ((getCloseContextMethod = EagerServiceGrpc.getCloseContextMethod) == null) {
      synchronized (EagerServiceGrpc.class) {
        if ((getCloseContextMethod = EagerServiceGrpc.getCloseContextMethod) == null) {
          EagerServiceGrpc.getCloseContextMethod = getCloseContextMethod =
              io.grpc.MethodDescriptor.<tensorflow.eager.EagerServiceOuterClass.CloseContextRequest, tensorflow.eager.EagerServiceOuterClass.CloseContextResponse>newBuilder()
              .setType(io.grpc.MethodDescriptor.MethodType.UNARY)
              .setFullMethodName(generateFullMethodName(SERVICE_NAME, "CloseContext"))
              .setSampledToLocalTracing(true)
              .setRequestMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.CloseContextRequest.getDefaultInstance()))
              .setResponseMarshaller(io.grpc.protobuf.ProtoUtils.marshaller(
                  tensorflow.eager.EagerServiceOuterClass.CloseContextResponse.getDefaultInstance()))
              .setSchemaDescriptor(new EagerServiceMethodDescriptorSupplier("CloseContext"))
              .build();
        }
      }
    }
    return getCloseContextMethod;
  }

  /**
   * Creates a new async stub that supports all call types for the service
   */
  public static EagerServiceStub newStub(io.grpc.Channel channel) {
    io.grpc.stub.AbstractStub.StubFactory<EagerServiceStub> factory =
      new io.grpc.stub.AbstractStub.StubFactory<EagerServiceStub>() {
        @java.lang.Override
        public EagerServiceStub newStub(io.grpc.Channel channel, io.grpc.CallOptions callOptions) {
          return new EagerServiceStub(channel, callOptions);
        }
      };
    return EagerServiceStub.newStub(factory, channel);
  }

  /**
   * Creates a new blocking-style stub that supports unary and streaming output calls on the service
   */
  public static EagerServiceBlockingStub newBlockingStub(
      io.grpc.Channel channel) {
    io.grpc.stub.AbstractStub.StubFactory<EagerServiceBlockingStub> factory =
      new io.grpc.stub.AbstractStub.StubFactory<EagerServiceBlockingStub>() {
        @java.lang.Override
        public EagerServiceBlockingStub newStub(io.grpc.Channel channel, io.grpc.CallOptions callOptions) {
          return new EagerServiceBlockingStub(channel, callOptions);
        }
      };
    return EagerServiceBlockingStub.newStub(factory, channel);
  }

  /**
   * Creates a new ListenableFuture-style stub that supports unary calls on the service
   */
  public static EagerServiceFutureStub newFutureStub(
      io.grpc.Channel channel) {
    io.grpc.stub.AbstractStub.StubFactory<EagerServiceFutureStub> factory =
      new io.grpc.stub.AbstractStub.StubFactory<EagerServiceFutureStub>() {
        @java.lang.Override
        public EagerServiceFutureStub newStub(io.grpc.Channel channel, io.grpc.CallOptions callOptions) {
          return new EagerServiceFutureStub(channel, callOptions);
        }
      };
    return EagerServiceFutureStub.newStub(factory, channel);
  }

  /**
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////////////
   * Eager Service defines a TensorFlow service that executes operations eagerly
   * on a set of local devices, on behalf of a remote Eager executor.
   * The service impl will keep track of the various clients and devices it has
   * access to and allows the client to enqueue ops on any devices that it is able
   * to access and schedule data transfers from/to any of the peers.
   * A client can generate multiple contexts to be able to independently execute
   * operations, but cannot share data between the two contexts.
   * NOTE: Even though contexts generated by clients should be independent, the
   * lower level tensorflow execution engine is not, so they might share some data
   * (e.g. a Device's ResourceMgr).
   * //////////////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static abstract class EagerServiceImplBase implements io.grpc.BindableService {

    /**
     * <pre>
     * This initializes the worker, informing it about the other workers in the
     * cluster and exchanging authentication tokens which will be used in all
     * other RPCs to detect whether the worker has restarted.
     * </pre>
     */
    public void createContext(tensorflow.eager.EagerServiceOuterClass.CreateContextRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.CreateContextResponse> responseObserver) {
      io.grpc.stub.ServerCalls.asyncUnimplementedUnaryCall(getCreateContextMethod(), responseObserver);
    }

    /**
     * <pre>
     * This updates the eager context on an existing worker when updating the set
     * of servers in a distributed eager cluster.
     * </pre>
     */
    public void updateContext(tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse> responseObserver) {
      io.grpc.stub.ServerCalls.asyncUnimplementedUnaryCall(getUpdateContextMethod(), responseObserver);
    }

    /**
     * <pre>
     * This takes a list of Execute and DeleteTensorHandle operations and enqueues
     * (in async mode) or executes (in sync mode) them on the remote server.
     * All outputs of ops which were not explicitly deleted with
     * DeleteTensorHandle entries will be assumed to be alive and are usable by
     * future calls to Enqueue.
     * </pre>
     */
    public void enqueue(tensorflow.eager.EagerServiceOuterClass.EnqueueRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> responseObserver) {
      io.grpc.stub.ServerCalls.asyncUnimplementedUnaryCall(getEnqueueMethod(), responseObserver);
    }

    /**
     * <pre>
     * A streaming version of Enqueue.
     * Current server implementation sends one response per received request.
     * The benefit for using a streaming version is that subsequent requests
     * can be sent without waiting for a response to the previous request. This
     * synchronization is required in the regular Enqueue call because gRPC does
     * not guarantee to preserve request order.
     * </pre>
     */
    public io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest> streamingEnqueue(
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> responseObserver) {
      return io.grpc.stub.ServerCalls.asyncUnimplementedStreamingCall(getStreamingEnqueueMethod(), responseObserver);
    }

    /**
     * <pre>
     * Takes a set of op IDs and waits until those ops are done. Returns any error
     * in the stream so far.
     * </pre>
     */
    public void waitQueueDone(tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse> responseObserver) {
      io.grpc.stub.ServerCalls.asyncUnimplementedUnaryCall(getWaitQueueDoneMethod(), responseObserver);
    }

    /**
     * <pre>
     * This takes an Eager operation and executes it in async mode on the remote
     * server. Different from EnqueueRequest, ops/functions sent through this
     * type of requests are allowed to execute in parallel and no ordering is
     * preserved by RPC stream or executor.
     * This request type should only be used for executing component functions.
     * Ordering of component functions should be enforced by their corresponding
     * main functions. The runtime ensures the following invarients for component
     * functions (CFs) and their main functions (MFs):
     * (1) MF1 -&gt; MF2 ==&gt; CF1 -&gt; CF2 ("-&gt;" indicates order of execution);
     * (2) MF1 || MF2 ==&gt; CF1 || CF2 ("||" indicates possible parallel execution);
     * (3) For CF1 and CF2 that come from the same MF, CF1 || CF2
     * For executing ops/main functions, use Enqueue or StreamingEnqueue instead
     * for correct ordering.
     * </pre>
     */
    public void runComponentFunction(tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse> responseObserver) {
      io.grpc.stub.ServerCalls.asyncUnimplementedUnaryCall(getRunComponentFunctionMethod(), responseObserver);
    }

    /**
     * <pre>
     * Contexts are always created with a deadline and no RPCs within a deadline
     * will trigger a context garbage collection. KeepAlive calls can be used to
     * delay this. It can also be used to validate the existence of a context ID
     * on remote eager worker. If the context is on remote worker, return the same
     * ID and the current context view ID. This is useful for checking if the
     * remote worker (potentially with the same task name and hostname / port) is
     * replaced with a new process.
     * </pre>
     */
    public void keepAlive(tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse> responseObserver) {
      io.grpc.stub.ServerCalls.asyncUnimplementedUnaryCall(getKeepAliveMethod(), responseObserver);
    }

    /**
     * <pre>
     * Closes the context. No calls to other methods using the existing context ID
     * are valid after this.
     * </pre>
     */
    public void closeContext(tensorflow.eager.EagerServiceOuterClass.CloseContextRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.CloseContextResponse> responseObserver) {
      io.grpc.stub.ServerCalls.asyncUnimplementedUnaryCall(getCloseContextMethod(), responseObserver);
    }

    @java.lang.Override public final io.grpc.ServerServiceDefinition bindService() {
      return io.grpc.ServerServiceDefinition.builder(getServiceDescriptor())
          .addMethod(
            getCreateContextMethod(),
            io.grpc.stub.ServerCalls.asyncUnaryCall(
              new MethodHandlers<
                tensorflow.eager.EagerServiceOuterClass.CreateContextRequest,
                tensorflow.eager.EagerServiceOuterClass.CreateContextResponse>(
                  this, METHODID_CREATE_CONTEXT)))
          .addMethod(
            getUpdateContextMethod(),
            io.grpc.stub.ServerCalls.asyncUnaryCall(
              new MethodHandlers<
                tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest,
                tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse>(
                  this, METHODID_UPDATE_CONTEXT)))
          .addMethod(
            getEnqueueMethod(),
            io.grpc.stub.ServerCalls.asyncUnaryCall(
              new MethodHandlers<
                tensorflow.eager.EagerServiceOuterClass.EnqueueRequest,
                tensorflow.eager.EagerServiceOuterClass.EnqueueResponse>(
                  this, METHODID_ENQUEUE)))
          .addMethod(
            getStreamingEnqueueMethod(),
            io.grpc.stub.ServerCalls.asyncBidiStreamingCall(
              new MethodHandlers<
                tensorflow.eager.EagerServiceOuterClass.EnqueueRequest,
                tensorflow.eager.EagerServiceOuterClass.EnqueueResponse>(
                  this, METHODID_STREAMING_ENQUEUE)))
          .addMethod(
            getWaitQueueDoneMethod(),
            io.grpc.stub.ServerCalls.asyncUnaryCall(
              new MethodHandlers<
                tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest,
                tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse>(
                  this, METHODID_WAIT_QUEUE_DONE)))
          .addMethod(
            getRunComponentFunctionMethod(),
            io.grpc.stub.ServerCalls.asyncUnaryCall(
              new MethodHandlers<
                tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest,
                tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse>(
                  this, METHODID_RUN_COMPONENT_FUNCTION)))
          .addMethod(
            getKeepAliveMethod(),
            io.grpc.stub.ServerCalls.asyncUnaryCall(
              new MethodHandlers<
                tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest,
                tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse>(
                  this, METHODID_KEEP_ALIVE)))
          .addMethod(
            getCloseContextMethod(),
            io.grpc.stub.ServerCalls.asyncUnaryCall(
              new MethodHandlers<
                tensorflow.eager.EagerServiceOuterClass.CloseContextRequest,
                tensorflow.eager.EagerServiceOuterClass.CloseContextResponse>(
                  this, METHODID_CLOSE_CONTEXT)))
          .build();
    }
  }

  /**
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////////////
   * Eager Service defines a TensorFlow service that executes operations eagerly
   * on a set of local devices, on behalf of a remote Eager executor.
   * The service impl will keep track of the various clients and devices it has
   * access to and allows the client to enqueue ops on any devices that it is able
   * to access and schedule data transfers from/to any of the peers.
   * A client can generate multiple contexts to be able to independently execute
   * operations, but cannot share data between the two contexts.
   * NOTE: Even though contexts generated by clients should be independent, the
   * lower level tensorflow execution engine is not, so they might share some data
   * (e.g. a Device's ResourceMgr).
   * //////////////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class EagerServiceStub extends io.grpc.stub.AbstractAsyncStub<EagerServiceStub> {
    private EagerServiceStub(
        io.grpc.Channel channel, io.grpc.CallOptions callOptions) {
      super(channel, callOptions);
    }

    @java.lang.Override
    protected EagerServiceStub build(
        io.grpc.Channel channel, io.grpc.CallOptions callOptions) {
      return new EagerServiceStub(channel, callOptions);
    }

    /**
     * <pre>
     * This initializes the worker, informing it about the other workers in the
     * cluster and exchanging authentication tokens which will be used in all
     * other RPCs to detect whether the worker has restarted.
     * </pre>
     */
    public void createContext(tensorflow.eager.EagerServiceOuterClass.CreateContextRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.CreateContextResponse> responseObserver) {
      io.grpc.stub.ClientCalls.asyncUnaryCall(
          getChannel().newCall(getCreateContextMethod(), getCallOptions()), request, responseObserver);
    }

    /**
     * <pre>
     * This updates the eager context on an existing worker when updating the set
     * of servers in a distributed eager cluster.
     * </pre>
     */
    public void updateContext(tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse> responseObserver) {
      io.grpc.stub.ClientCalls.asyncUnaryCall(
          getChannel().newCall(getUpdateContextMethod(), getCallOptions()), request, responseObserver);
    }

    /**
     * <pre>
     * This takes a list of Execute and DeleteTensorHandle operations and enqueues
     * (in async mode) or executes (in sync mode) them on the remote server.
     * All outputs of ops which were not explicitly deleted with
     * DeleteTensorHandle entries will be assumed to be alive and are usable by
     * future calls to Enqueue.
     * </pre>
     */
    public void enqueue(tensorflow.eager.EagerServiceOuterClass.EnqueueRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> responseObserver) {
      io.grpc.stub.ClientCalls.asyncUnaryCall(
          getChannel().newCall(getEnqueueMethod(), getCallOptions()), request, responseObserver);
    }

    /**
     * <pre>
     * A streaming version of Enqueue.
     * Current server implementation sends one response per received request.
     * The benefit for using a streaming version is that subsequent requests
     * can be sent without waiting for a response to the previous request. This
     * synchronization is required in the regular Enqueue call because gRPC does
     * not guarantee to preserve request order.
     * </pre>
     */
    public io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.EnqueueRequest> streamingEnqueue(
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> responseObserver) {
      return io.grpc.stub.ClientCalls.asyncBidiStreamingCall(
          getChannel().newCall(getStreamingEnqueueMethod(), getCallOptions()), responseObserver);
    }

    /**
     * <pre>
     * Takes a set of op IDs and waits until those ops are done. Returns any error
     * in the stream so far.
     * </pre>
     */
    public void waitQueueDone(tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse> responseObserver) {
      io.grpc.stub.ClientCalls.asyncUnaryCall(
          getChannel().newCall(getWaitQueueDoneMethod(), getCallOptions()), request, responseObserver);
    }

    /**
     * <pre>
     * This takes an Eager operation and executes it in async mode on the remote
     * server. Different from EnqueueRequest, ops/functions sent through this
     * type of requests are allowed to execute in parallel and no ordering is
     * preserved by RPC stream or executor.
     * This request type should only be used for executing component functions.
     * Ordering of component functions should be enforced by their corresponding
     * main functions. The runtime ensures the following invarients for component
     * functions (CFs) and their main functions (MFs):
     * (1) MF1 -&gt; MF2 ==&gt; CF1 -&gt; CF2 ("-&gt;" indicates order of execution);
     * (2) MF1 || MF2 ==&gt; CF1 || CF2 ("||" indicates possible parallel execution);
     * (3) For CF1 and CF2 that come from the same MF, CF1 || CF2
     * For executing ops/main functions, use Enqueue or StreamingEnqueue instead
     * for correct ordering.
     * </pre>
     */
    public void runComponentFunction(tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse> responseObserver) {
      io.grpc.stub.ClientCalls.asyncUnaryCall(
          getChannel().newCall(getRunComponentFunctionMethod(), getCallOptions()), request, responseObserver);
    }

    /**
     * <pre>
     * Contexts are always created with a deadline and no RPCs within a deadline
     * will trigger a context garbage collection. KeepAlive calls can be used to
     * delay this. It can also be used to validate the existence of a context ID
     * on remote eager worker. If the context is on remote worker, return the same
     * ID and the current context view ID. This is useful for checking if the
     * remote worker (potentially with the same task name and hostname / port) is
     * replaced with a new process.
     * </pre>
     */
    public void keepAlive(tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse> responseObserver) {
      io.grpc.stub.ClientCalls.asyncUnaryCall(
          getChannel().newCall(getKeepAliveMethod(), getCallOptions()), request, responseObserver);
    }

    /**
     * <pre>
     * Closes the context. No calls to other methods using the existing context ID
     * are valid after this.
     * </pre>
     */
    public void closeContext(tensorflow.eager.EagerServiceOuterClass.CloseContextRequest request,
        io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.CloseContextResponse> responseObserver) {
      io.grpc.stub.ClientCalls.asyncUnaryCall(
          getChannel().newCall(getCloseContextMethod(), getCallOptions()), request, responseObserver);
    }
  }

  /**
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////////////
   * Eager Service defines a TensorFlow service that executes operations eagerly
   * on a set of local devices, on behalf of a remote Eager executor.
   * The service impl will keep track of the various clients and devices it has
   * access to and allows the client to enqueue ops on any devices that it is able
   * to access and schedule data transfers from/to any of the peers.
   * A client can generate multiple contexts to be able to independently execute
   * operations, but cannot share data between the two contexts.
   * NOTE: Even though contexts generated by clients should be independent, the
   * lower level tensorflow execution engine is not, so they might share some data
   * (e.g. a Device's ResourceMgr).
   * //////////////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class EagerServiceBlockingStub extends io.grpc.stub.AbstractBlockingStub<EagerServiceBlockingStub> {
    private EagerServiceBlockingStub(
        io.grpc.Channel channel, io.grpc.CallOptions callOptions) {
      super(channel, callOptions);
    }

    @java.lang.Override
    protected EagerServiceBlockingStub build(
        io.grpc.Channel channel, io.grpc.CallOptions callOptions) {
      return new EagerServiceBlockingStub(channel, callOptions);
    }

    /**
     * <pre>
     * This initializes the worker, informing it about the other workers in the
     * cluster and exchanging authentication tokens which will be used in all
     * other RPCs to detect whether the worker has restarted.
     * </pre>
     */
    public tensorflow.eager.EagerServiceOuterClass.CreateContextResponse createContext(tensorflow.eager.EagerServiceOuterClass.CreateContextRequest request) {
      return io.grpc.stub.ClientCalls.blockingUnaryCall(
          getChannel(), getCreateContextMethod(), getCallOptions(), request);
    }

    /**
     * <pre>
     * This updates the eager context on an existing worker when updating the set
     * of servers in a distributed eager cluster.
     * </pre>
     */
    public tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse updateContext(tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest request) {
      return io.grpc.stub.ClientCalls.blockingUnaryCall(
          getChannel(), getUpdateContextMethod(), getCallOptions(), request);
    }

    /**
     * <pre>
     * This takes a list of Execute and DeleteTensorHandle operations and enqueues
     * (in async mode) or executes (in sync mode) them on the remote server.
     * All outputs of ops which were not explicitly deleted with
     * DeleteTensorHandle entries will be assumed to be alive and are usable by
     * future calls to Enqueue.
     * </pre>
     */
    public tensorflow.eager.EagerServiceOuterClass.EnqueueResponse enqueue(tensorflow.eager.EagerServiceOuterClass.EnqueueRequest request) {
      return io.grpc.stub.ClientCalls.blockingUnaryCall(
          getChannel(), getEnqueueMethod(), getCallOptions(), request);
    }

    /**
     * <pre>
     * Takes a set of op IDs and waits until those ops are done. Returns any error
     * in the stream so far.
     * </pre>
     */
    public tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse waitQueueDone(tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest request) {
      return io.grpc.stub.ClientCalls.blockingUnaryCall(
          getChannel(), getWaitQueueDoneMethod(), getCallOptions(), request);
    }

    /**
     * <pre>
     * This takes an Eager operation and executes it in async mode on the remote
     * server. Different from EnqueueRequest, ops/functions sent through this
     * type of requests are allowed to execute in parallel and no ordering is
     * preserved by RPC stream or executor.
     * This request type should only be used for executing component functions.
     * Ordering of component functions should be enforced by their corresponding
     * main functions. The runtime ensures the following invarients for component
     * functions (CFs) and their main functions (MFs):
     * (1) MF1 -&gt; MF2 ==&gt; CF1 -&gt; CF2 ("-&gt;" indicates order of execution);
     * (2) MF1 || MF2 ==&gt; CF1 || CF2 ("||" indicates possible parallel execution);
     * (3) For CF1 and CF2 that come from the same MF, CF1 || CF2
     * For executing ops/main functions, use Enqueue or StreamingEnqueue instead
     * for correct ordering.
     * </pre>
     */
    public tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse runComponentFunction(tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest request) {
      return io.grpc.stub.ClientCalls.blockingUnaryCall(
          getChannel(), getRunComponentFunctionMethod(), getCallOptions(), request);
    }

    /**
     * <pre>
     * Contexts are always created with a deadline and no RPCs within a deadline
     * will trigger a context garbage collection. KeepAlive calls can be used to
     * delay this. It can also be used to validate the existence of a context ID
     * on remote eager worker. If the context is on remote worker, return the same
     * ID and the current context view ID. This is useful for checking if the
     * remote worker (potentially with the same task name and hostname / port) is
     * replaced with a new process.
     * </pre>
     */
    public tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse keepAlive(tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest request) {
      return io.grpc.stub.ClientCalls.blockingUnaryCall(
          getChannel(), getKeepAliveMethod(), getCallOptions(), request);
    }

    /**
     * <pre>
     * Closes the context. No calls to other methods using the existing context ID
     * are valid after this.
     * </pre>
     */
    public tensorflow.eager.EagerServiceOuterClass.CloseContextResponse closeContext(tensorflow.eager.EagerServiceOuterClass.CloseContextRequest request) {
      return io.grpc.stub.ClientCalls.blockingUnaryCall(
          getChannel(), getCloseContextMethod(), getCallOptions(), request);
    }
  }

  /**
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////////////
   * Eager Service defines a TensorFlow service that executes operations eagerly
   * on a set of local devices, on behalf of a remote Eager executor.
   * The service impl will keep track of the various clients and devices it has
   * access to and allows the client to enqueue ops on any devices that it is able
   * to access and schedule data transfers from/to any of the peers.
   * A client can generate multiple contexts to be able to independently execute
   * operations, but cannot share data between the two contexts.
   * NOTE: Even though contexts generated by clients should be independent, the
   * lower level tensorflow execution engine is not, so they might share some data
   * (e.g. a Device's ResourceMgr).
   * //////////////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class EagerServiceFutureStub extends io.grpc.stub.AbstractFutureStub<EagerServiceFutureStub> {
    private EagerServiceFutureStub(
        io.grpc.Channel channel, io.grpc.CallOptions callOptions) {
      super(channel, callOptions);
    }

    @java.lang.Override
    protected EagerServiceFutureStub build(
        io.grpc.Channel channel, io.grpc.CallOptions callOptions) {
      return new EagerServiceFutureStub(channel, callOptions);
    }

    /**
     * <pre>
     * This initializes the worker, informing it about the other workers in the
     * cluster and exchanging authentication tokens which will be used in all
     * other RPCs to detect whether the worker has restarted.
     * </pre>
     */
    public com.google.common.util.concurrent.ListenableFuture<tensorflow.eager.EagerServiceOuterClass.CreateContextResponse> createContext(
        tensorflow.eager.EagerServiceOuterClass.CreateContextRequest request) {
      return io.grpc.stub.ClientCalls.futureUnaryCall(
          getChannel().newCall(getCreateContextMethod(), getCallOptions()), request);
    }

    /**
     * <pre>
     * This updates the eager context on an existing worker when updating the set
     * of servers in a distributed eager cluster.
     * </pre>
     */
    public com.google.common.util.concurrent.ListenableFuture<tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse> updateContext(
        tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest request) {
      return io.grpc.stub.ClientCalls.futureUnaryCall(
          getChannel().newCall(getUpdateContextMethod(), getCallOptions()), request);
    }

    /**
     * <pre>
     * This takes a list of Execute and DeleteTensorHandle operations and enqueues
     * (in async mode) or executes (in sync mode) them on the remote server.
     * All outputs of ops which were not explicitly deleted with
     * DeleteTensorHandle entries will be assumed to be alive and are usable by
     * future calls to Enqueue.
     * </pre>
     */
    public com.google.common.util.concurrent.ListenableFuture<tensorflow.eager.EagerServiceOuterClass.EnqueueResponse> enqueue(
        tensorflow.eager.EagerServiceOuterClass.EnqueueRequest request) {
      return io.grpc.stub.ClientCalls.futureUnaryCall(
          getChannel().newCall(getEnqueueMethod(), getCallOptions()), request);
    }

    /**
     * <pre>
     * Takes a set of op IDs and waits until those ops are done. Returns any error
     * in the stream so far.
     * </pre>
     */
    public com.google.common.util.concurrent.ListenableFuture<tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse> waitQueueDone(
        tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest request) {
      return io.grpc.stub.ClientCalls.futureUnaryCall(
          getChannel().newCall(getWaitQueueDoneMethod(), getCallOptions()), request);
    }

    /**
     * <pre>
     * This takes an Eager operation and executes it in async mode on the remote
     * server. Different from EnqueueRequest, ops/functions sent through this
     * type of requests are allowed to execute in parallel and no ordering is
     * preserved by RPC stream or executor.
     * This request type should only be used for executing component functions.
     * Ordering of component functions should be enforced by their corresponding
     * main functions. The runtime ensures the following invarients for component
     * functions (CFs) and their main functions (MFs):
     * (1) MF1 -&gt; MF2 ==&gt; CF1 -&gt; CF2 ("-&gt;" indicates order of execution);
     * (2) MF1 || MF2 ==&gt; CF1 || CF2 ("||" indicates possible parallel execution);
     * (3) For CF1 and CF2 that come from the same MF, CF1 || CF2
     * For executing ops/main functions, use Enqueue or StreamingEnqueue instead
     * for correct ordering.
     * </pre>
     */
    public com.google.common.util.concurrent.ListenableFuture<tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse> runComponentFunction(
        tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest request) {
      return io.grpc.stub.ClientCalls.futureUnaryCall(
          getChannel().newCall(getRunComponentFunctionMethod(), getCallOptions()), request);
    }

    /**
     * <pre>
     * Contexts are always created with a deadline and no RPCs within a deadline
     * will trigger a context garbage collection. KeepAlive calls can be used to
     * delay this. It can also be used to validate the existence of a context ID
     * on remote eager worker. If the context is on remote worker, return the same
     * ID and the current context view ID. This is useful for checking if the
     * remote worker (potentially with the same task name and hostname / port) is
     * replaced with a new process.
     * </pre>
     */
    public com.google.common.util.concurrent.ListenableFuture<tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse> keepAlive(
        tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest request) {
      return io.grpc.stub.ClientCalls.futureUnaryCall(
          getChannel().newCall(getKeepAliveMethod(), getCallOptions()), request);
    }

    /**
     * <pre>
     * Closes the context. No calls to other methods using the existing context ID
     * are valid after this.
     * </pre>
     */
    public com.google.common.util.concurrent.ListenableFuture<tensorflow.eager.EagerServiceOuterClass.CloseContextResponse> closeContext(
        tensorflow.eager.EagerServiceOuterClass.CloseContextRequest request) {
      return io.grpc.stub.ClientCalls.futureUnaryCall(
          getChannel().newCall(getCloseContextMethod(), getCallOptions()), request);
    }
  }

  private static final int METHODID_CREATE_CONTEXT = 0;
  private static final int METHODID_UPDATE_CONTEXT = 1;
  private static final int METHODID_ENQUEUE = 2;
  private static final int METHODID_WAIT_QUEUE_DONE = 3;
  private static final int METHODID_RUN_COMPONENT_FUNCTION = 4;
  private static final int METHODID_KEEP_ALIVE = 5;
  private static final int METHODID_CLOSE_CONTEXT = 6;
  private static final int METHODID_STREAMING_ENQUEUE = 7;

  private static final class MethodHandlers<Req, Resp> implements
      io.grpc.stub.ServerCalls.UnaryMethod<Req, Resp>,
      io.grpc.stub.ServerCalls.ServerStreamingMethod<Req, Resp>,
      io.grpc.stub.ServerCalls.ClientStreamingMethod<Req, Resp>,
      io.grpc.stub.ServerCalls.BidiStreamingMethod<Req, Resp> {
    private final EagerServiceImplBase serviceImpl;
    private final int methodId;

    MethodHandlers(EagerServiceImplBase serviceImpl, int methodId) {
      this.serviceImpl = serviceImpl;
      this.methodId = methodId;
    }

    @java.lang.Override
    @java.lang.SuppressWarnings("unchecked")
    public void invoke(Req request, io.grpc.stub.StreamObserver<Resp> responseObserver) {
      switch (methodId) {
        case METHODID_CREATE_CONTEXT:
          serviceImpl.createContext((tensorflow.eager.EagerServiceOuterClass.CreateContextRequest) request,
              (io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.CreateContextResponse>) responseObserver);
          break;
        case METHODID_UPDATE_CONTEXT:
          serviceImpl.updateContext((tensorflow.eager.EagerServiceOuterClass.UpdateContextRequest) request,
              (io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.UpdateContextResponse>) responseObserver);
          break;
        case METHODID_ENQUEUE:
          serviceImpl.enqueue((tensorflow.eager.EagerServiceOuterClass.EnqueueRequest) request,
              (io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.EnqueueResponse>) responseObserver);
          break;
        case METHODID_WAIT_QUEUE_DONE:
          serviceImpl.waitQueueDone((tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneRequest) request,
              (io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.WaitQueueDoneResponse>) responseObserver);
          break;
        case METHODID_RUN_COMPONENT_FUNCTION:
          serviceImpl.runComponentFunction((tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionRequest) request,
              (io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.RunComponentFunctionResponse>) responseObserver);
          break;
        case METHODID_KEEP_ALIVE:
          serviceImpl.keepAlive((tensorflow.eager.EagerServiceOuterClass.KeepAliveRequest) request,
              (io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.KeepAliveResponse>) responseObserver);
          break;
        case METHODID_CLOSE_CONTEXT:
          serviceImpl.closeContext((tensorflow.eager.EagerServiceOuterClass.CloseContextRequest) request,
              (io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.CloseContextResponse>) responseObserver);
          break;
        default:
          throw new AssertionError();
      }
    }

    @java.lang.Override
    @java.lang.SuppressWarnings("unchecked")
    public io.grpc.stub.StreamObserver<Req> invoke(
        io.grpc.stub.StreamObserver<Resp> responseObserver) {
      switch (methodId) {
        case METHODID_STREAMING_ENQUEUE:
          return (io.grpc.stub.StreamObserver<Req>) serviceImpl.streamingEnqueue(
              (io.grpc.stub.StreamObserver<tensorflow.eager.EagerServiceOuterClass.EnqueueResponse>) responseObserver);
        default:
          throw new AssertionError();
      }
    }
  }

  private static abstract class EagerServiceBaseDescriptorSupplier
      implements io.grpc.protobuf.ProtoFileDescriptorSupplier, io.grpc.protobuf.ProtoServiceDescriptorSupplier {
    EagerServiceBaseDescriptorSupplier() {}

    @java.lang.Override
    public com.google.protobuf.Descriptors.FileDescriptor getFileDescriptor() {
      return tensorflow.eager.EagerServiceOuterClass.getDescriptor();
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.ServiceDescriptor getServiceDescriptor() {
      return getFileDescriptor().findServiceByName("EagerService");
    }
  }

  private static final class EagerServiceFileDescriptorSupplier
      extends EagerServiceBaseDescriptorSupplier {
    EagerServiceFileDescriptorSupplier() {}
  }

  private static final class EagerServiceMethodDescriptorSupplier
      extends EagerServiceBaseDescriptorSupplier
      implements io.grpc.protobuf.ProtoMethodDescriptorSupplier {
    private final String methodName;

    EagerServiceMethodDescriptorSupplier(String methodName) {
      this.methodName = methodName;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.MethodDescriptor getMethodDescriptor() {
      return getServiceDescriptor().findMethodByName(methodName);
    }
  }

  private static volatile io.grpc.ServiceDescriptor serviceDescriptor;

  public static io.grpc.ServiceDescriptor getServiceDescriptor() {
    io.grpc.ServiceDescriptor result = serviceDescriptor;
    if (result == null) {
      synchronized (EagerServiceGrpc.class) {
        result = serviceDescriptor;
        if (result == null) {
          serviceDescriptor = result = io.grpc.ServiceDescriptor.newBuilder(SERVICE_NAME)
              .setSchemaDescriptor(new EagerServiceFileDescriptorSupplier())
              .addMethod(getCreateContextMethod())
              .addMethod(getUpdateContextMethod())
              .addMethod(getEnqueueMethod())
              .addMethod(getStreamingEnqueueMethod())
              .addMethod(getWaitQueueDoneMethod())
              .addMethod(getRunComponentFunctionMethod())
              .addMethod(getKeepAliveMethod())
              .addMethod(getCloseContextMethod())
              .build();
        }
      }
    }
    return result;
  }
}
